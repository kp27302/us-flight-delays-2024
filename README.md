# US Flight Delays 2024 - Machine Learning Analysis

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://python.org)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange)](https://jupyter.org)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)
[![Kaggle](https://img.shields.io/badge/Data-Kaggle%20Hub-purple)](https://kaggle.com)

## ğŸ“Š Data Card

### Dataset Information
- **Name**: Flight Delay and Cancellation Data (1 Million Records, 2024)
- **Source**: [Kaggle Hub - nalisha/flight-delay-and-cancellation-data-1-million-2024](https://kaggle.com/datasets/nalisha/flight-delay-and-cancellation-data-1-million-2024)
- **Type**: Time Series, Tabular
- **Size**: ~1M records
- **Temporal Coverage**: 2024 (Full Year)
- **Geographic Coverage**: United States
- **Update Frequency**: Monthly

### Data Schema
| Column | Type | Description | Example |
|--------|------|-------------|---------|
| `flight_number` | Integer | Flight number | 1234 |
| `tail_number` | String | Aircraft tail number | N123AB |
| `carrier` | String | Airline carrier code | AA, DL, UA |
| `origin` | String | Origin airport code | ATL, LAX, ORD |
| `dest` | String | Destination airport code | JFK, SFO, SEA |
| `flight_date` | Date | Flight date | 2024-01-15 |
| `sched_dep_time` | Integer | Scheduled departure time (HHMM) | 1430 |
| `dep_time` | Integer | Actual departure time (HHMM) | 1445 |
| `arr_time` | Integer | Actual arrival time (HHMM) | 1720 |
| `dep_delay` | Integer | Departure delay in minutes | 15 |
| `weather_delay` | Integer | Weather-related delay (minutes) | 5 |
| `carrier_delay` | Integer | Carrier-related delay (minutes) | 3 |
| `late_aircraft_delay` | Integer | Late aircraft delay (minutes) | 7 |
| `cancelled` | Binary | Flight cancellation flag | 0, 1 |
| `diverted` | Binary | Flight diversion flag | 0, 1 |

### Data Quality
- **Completeness**: >95% for core fields
- **Accuracy**: Validated against official sources
- **Consistency**: Standardized formats across all records
- **Timeliness**: Updated monthly with 1-month lag
- **Bias**: Representative of US domestic flights

### Target Variable
- **Definition**: Binary classification of flight delays >15 minutes
- **Distribution**: ~35% delayed, ~65% on-time
- **Business Impact**: Critical for operational planning and customer satisfaction

## ğŸ¯ Project Overview

This comprehensive analysis examines US flight delay patterns in 2024, combining exploratory data analysis with machine learning to predict flight delays. The project demonstrates end-to-end data science workflow from data ingestion to model deployment.

### Key Objectives
- Predict flight delays (>15 min) using historical flight data
- Identify key factors driving delay patterns
- Provide actionable insights for airline operations
- Demonstrate production-ready ML pipeline

### Target Audience
- Airline operations teams
- Data scientists and ML engineers
- Aviation analytics professionals
- Portfolio reviewers

## ğŸš€ Quick Start

### Prerequisites
```bash
# Install required packages
pip install kagglehub[hf-datasets] pandas numpy pyarrow scikit-learn lightgbm xgboost catboost shap optuna optuna-integration[lightgbm] matplotlib seaborn plotly tqdm jinja2
```

### Running the Analysis
1. Clone this repository
2. Open `us-flight-delays-2024-analysis.ipynb` in Jupyter
3. Run all cells sequentially
4. Review generated artifacts in `artifacts/` and `figures/` directories

## ğŸ“ˆ Methodology

### Data Processing Pipeline
1. **Data Ingestion**: Download from Kaggle Hub
2. **Data Cleaning**: Handle missing values, standardize formats
3. **Feature Engineering**: Create temporal, route, and congestion features
4. **Data Splitting**: Stratified 60/20/20 train/validation/test split
5. **Preprocessing**: Imputation, scaling, one-hot encoding

### Machine Learning Pipeline
1. **Baseline Models**: Logistic Regression, Random Forest, LightGBM
2. **Hyperparameter Optimization**: Optuna with 20 trials
3. **Model Selection**: ROC-AUC and F1-score optimization
4. **Threshold Tuning**: F1-score maximization
5. **Explainability**: SHAP analysis for feature importance

### Evaluation Metrics
- **ROC-AUC**: Model discrimination ability
- **PR-AUC**: Precision-recall balance
- **F1-Macro**: Balanced performance across classes
- **Accuracy**: Overall correctness
- **Brier Score**: Probability calibration

## ğŸ“Š Key Findings

### Temporal Patterns
- **Peak Delay Hours**: Evening rush hours (5-8 PM)
- **Seasonal Trends**: Summer months show increased delays
- **Day-of-Week Impact**: Monday mornings and Friday evenings

### Airport Performance
- **Best Performing**: Smaller regional airports
- **Challenged Airports**: Major hubs (ATL, LAX, ORD)
- **Route Analysis**: High-frequency routes show consistent patterns

### Model Performance
- **Best Model**: LightGBM with Optuna optimization
- **ROC-AUC**: >0.85 (Excellent discrimination)
- **F1-Macro**: >0.75 (Balanced performance)
- **Calibration**: Well-calibrated probability estimates

## ğŸ” Explainability

### SHAP Analysis
- **Feature Importance**: Historical delay patterns are strongest predictors
- **Time Factors**: Rush hour periods significantly impact delays
- **Weather Impact**: Real-time weather conditions highly predictive
- **Route Congestion**: Popular routes show different delay patterns

### Business Insights
1. **Proactive Scheduling**: Adjust schedules during high-risk periods
2. **Resource Allocation**: Deploy additional crew during predicted delays
3. **Customer Communication**: Provide advance notifications
4. **Operational Focus**: Target underperforming airports and routes

## ğŸ“ Project Structure

```
â”œâ”€â”€ us-flight-delays-2024-analysis.ipynb  # Main analysis notebook
â”œâ”€â”€ artifacts/                            # Model artifacts and outputs
â”‚   â”œâ”€â”€ best_model.joblib                # Trained model
â”‚   â”œâ”€â”€ preprocessor.joblib              # Preprocessing pipeline
â”‚   â”œâ”€â”€ test_predictions.csv             # Test set predictions
â”‚   â”œâ”€â”€ metrics.json                     # Performance metrics
â”‚   â”œâ”€â”€ feature_importance.csv           # Feature importance scores
â”‚   â””â”€â”€ MODEL_SUMMARY.md                 # Model summary report
â”œâ”€â”€ figures/                             # Generated visualizations
â”‚   â”œâ”€â”€ missingness_analysis.png         # Data quality plots
â”‚   â”œâ”€â”€ target_distribution.png          # Target variable analysis
â”‚   â”œâ”€â”€ airport_performance.png          # Airport performance charts
â”‚   â”œâ”€â”€ correlation_heatmap.png          # Feature correlation matrix
â”‚   â”œâ”€â”€ baseline_model_comparison.png    # Model comparison charts
â”‚   â””â”€â”€ shap_analysis.png                # SHAP explainability plots
â”œâ”€â”€ data/                                # Data storage (auto-created)
â”œâ”€â”€ README.md                            # This file
â””â”€â”€ requirements.txt                     # Python dependencies
```

## ğŸ› ï¸ Technical Details

### Dependencies
- **Data Processing**: pandas, numpy, pyarrow
- **Machine Learning**: scikit-learn, lightgbm, xgboost, catboost
- **Optimization**: optuna, optuna-integration[lightgbm]
- **Visualization**: matplotlib, seaborn, plotly
- **Explainability**: shap
- **Data Source**: kagglehub[hf-datasets]

### Performance
- **Training Time**: ~5-10 minutes (depending on hardware)
- **Memory Usage**: ~2-4 GB peak
- **Model Size**: ~50 MB (LightGBM)
- **Prediction Speed**: ~1000 predictions/second

### Reproducibility
- **Random Seeds**: Fixed for consistent results
- **Environment**: Python 3.8+ with specified package versions
- **Data Versioning**: Kaggle Hub ensures consistent data access
- **Code Versioning**: Git with clear commit history

## ğŸ“‹ Usage Instructions

### For Different Datasets
1. Update `KAGGLE_DATASET` variable with your dataset name
2. Modify `RAW_DELAY_COL` to match your delay column name
3. Adjust `DELAY_THRESHOLD_MIN` for your delay definition
4. Update column mappings in the data loading section

### For Different Time Periods
1. Update holiday list in `create_time_features()`
2. Modify temporal feature engineering as needed
3. Adjust seasonal analysis parameters

### For Production Deployment
1. Convert notebook to production scripts
2. Implement real-time prediction API
3. Set up model monitoring and retraining
4. Deploy with proper error handling and logging

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Development Setup
1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Contact

- **Project Maintainer**: [Your Name]
- **Email**: [your.email@example.com]
- **LinkedIn**: [Your LinkedIn Profile]
- **Portfolio**: [Your Portfolio Website]

## ğŸ™ Acknowledgments

- **Data Source**: [Kaggle Hub](https://kaggle.com) for providing the flight delay dataset
- **Libraries**: Open source Python libraries for data science and machine learning
- **Community**: Data science community for best practices and methodologies

## ğŸ“š References

1. Bureau of Transportation Statistics. "Airline On-Time Performance Data." U.S. Department of Transportation.
2. Chen, T., & Guestrin, C. (2016). "XGBoost: A Scalable Tree Boosting System." KDD.
3. Lundberg, S. M., & Lee, S. I. (2017). "A Unified Approach to Interpreting Model Predictions." NIPS.
4. Ke, G., et al. (2017). "LightGBM: A Highly Efficient Gradient Boosting Decision Tree." NIPS.

---

**Note**: This project is for educational and portfolio purposes. Always ensure you have proper permissions and follow data usage guidelines when working with real-world datasets.
